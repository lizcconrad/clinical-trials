<clinical_study>
  <!-- This xml conforms to an XML Schema at:
    https://clinicaltrials.gov/ct2/html/images/info/public.xsd -->
  <required_header>
    <download_date>ClinicalTrials.gov processed this data on May 29, 2018</download_date>
    <link_text>Link to the current ClinicalTrials.gov record.</link_text>
    <url>https://clinicaltrials.gov/show/NCT03312270</url>
  </required_header>
  <id_info>
    <org_study_id>01446r</org_study_id>
    <nct_id>NCT03312270</nct_id>
  </id_info>
  <brief_title>Strategies to Accommodate Reading (STAR)</brief_title>
  <acronym>STAR</acronym>
  <official_title>Strategies to Accommodate Reading (STAR): Using Assistive Technology to Support Reading by People With Aphasia.</official_title>
  <sponsors>
    <lead_sponsor>
      <agency>Miami University</agency>
      <agency_class>Other</agency_class>
    </lead_sponsor>
    <collaborator>
      <agency>Duquesne University</agency>
      <agency_class>Other</agency_class>
    </collaborator>
    <collaborator>
      <agency>University of Arizona</agency>
      <agency_class>Other</agency_class>
    </collaborator>
    <collaborator>
      <agency>University of Nebraska Lincoln</agency>
      <agency_class>Other</agency_class>
    </collaborator>
  </sponsors>
  <source>Miami University</source>
  <oversight_info>
    <has_dmc>No</has_dmc>
    <is_fda_regulated_drug>No</is_fda_regulated_drug>
    <is_fda_regulated_device>No</is_fda_regulated_device>
  </oversight_info>
  <brief_summary>
    <textblock>
      People with aphasia often understand spoken utterances better than written sentences. They
      also benefit from having content appear in multiple rather than single modalities. Because
      text-to-speech (TTS) systems accommodate both of these functions, it provides an ideal basis
      for a reading intervention. TTS systems convert written text to provide both text and
      auditory information. Research about using TTS supports with people with aphasia has not
      extended beyond basic case studies and our studies of sentence level comprehension. Hence, no
      evidence exists about varying TTS features—such as speech output, speech rate, and text
      highlighting—known to benefit others with reading problems. Also, social acceptance of TTS is
      not well understood, even though it is critical to adoption and long-term use of the
      technology.

      The purpose of this study is to evaluate various aspects of multimodality presentation of
      material through TTS systems used by people with aphasia. The immediate outcome of the
      proposed research will be evidence-based recommendations for selecting and adjusting TTS
      systems and features. This work will enable clinicians to maximize benefits for adults with
      varying aphasia profiles. We also will obtain initial evidence about the social validity and
      perceived value of TTS system use for this population.
    </textblock>
  </brief_summary>
  <detailed_description>
    <textblock>
      Experimental Procedures

        -  Phase 1: After completing the assessment session, phase one will include up to 4
           sessions each lasting up to 90 minutes. Across the four sessions, the participants will
           listen to and/or read 36 passages ranging from 4 to 6 sentences each. Then, participants
           will answer 10 multiple choice questions related to the content of the passage. The
           researcher will provide comprehension support via written choice strategy for the
           multiple choice questions (e.g., written and spoken language, nonverbal supports such as
           pointing). Participants will read and/or listen to the stories via a computer. An
           example of these questions appears in Appendix G.

        -  Phase 2: After completing the assessment session, phase two will include 1 to 3 separate
           parts examining 3 different TTS features (e.g., speech presentation rate, text
           highlighting, speech production quality). Participants can choose to participate in 1 or
           more parts within this phase. For each part, participants will first listen to or view
           selected variations of a target feature and choose their preferred variation. For each
           study, participants will then complete five or four experimental sessions lasting up to
           90 minutes each. Parts with up to five sessions (i.e., Part 1 and 2) will include
           features with more variations than those included in Part 3, which will include up to
           four sessions. Participants will read and/or listen to up to 12 reading passages in each
           session and answer multiple choice comprehension questions related to the content of the
           passage. At the conclusion of each session, participants will provide their opinion
           about the optimal targeted feature variation using rating forms and interview questions.
           Participants will read and/or listen to the passages via a computer.

        -  Phase 3: After completing the assessment session and any previous study phases, the
           participants will complete one 2-hour session. Participants will complete three
           activities: (1) education and system exploration guided by a member of the research
           team, (2) satisfaction and predicted use ratings of TTS systems, and (3) semi-structured
           interviews. Ratings of the TTS systems will be complete using Likert ratings scales (see
           Appendix H). Semi-structured interview questions will relate to rationales for system
           ratings and perceived application of TTS systems for functional use.
    </textblock>
  </detailed_description>
  <overall_status>Not yet recruiting</overall_status>
  <start_date type="Anticipated">May 1, 2018</start_date>
  <completion_date type="Anticipated">September 1, 2020</completion_date>
  <primary_completion_date type="Anticipated">September 1, 2020</primary_completion_date>
  <phase>N/A</phase>
  <study_type>Interventional</study_type>
  <has_expanded_access>No</has_expanded_access>
  <study_design_info>
    <intervention_model>Single Group Assignment</intervention_model>
    <intervention_model_description>Examination of comprehension differences when information is presented under different conditions: (a) written only, (b) auditory only or (c) combined written and auditory.</intervention_model_description>
    <primary_purpose>Supportive Care</primary_purpose>
    <masking>None (Open Label)</masking>
  </study_design_info>
  <primary_outcome>
    <measure>1. What is the accuracy with which people with aphasia comprehend paragraph-level information presented as single modalities (auditory or written) versus multiple modalities (written and auditory)?</measure>
    <time_frame>4 sessions, 9 minutes each over the course of 1 month</time_frame>
    <description>Participants will answer questions after listening and/or reading stories</description>
  </primary_outcome>
  <secondary_outcome>
    <measure>Which text-to-speech systems feature variations do people with aphasia prefer and derive the most benefit in terms of comprehension accuracy?</measure>
    <time_frame>Up to 5 sessions, 90 minutes each over the course of 1 month</time_frame>
    <description>Read stories, answer multiple choice questions. Identify feature preferences.</description>
  </secondary_outcome>
  <secondary_outcome>
    <measure>3. How do people with aphasia perceive and behave when using currently available text-to-speech systems?</measure>
    <time_frame>1 session lasting up to 2 hours</time_frame>
    <description>Participants will learn about text-to-speech systems and complete interview about preferences</description>
  </secondary_outcome>
  <number_of_arms>1</number_of_arms>
  <enrollment type="Anticipated">150</enrollment>
  <condition>Aphasia</condition>
  <arm_group>
    <arm_group_label>Multimodality information Comprehension</arm_group_label>
    <arm_group_type>Experimental</arm_group_type>
    <description>Evaluate various aspects of multimodality presentation of materials through text-to-speech systems used by people with aphasia.</description>
  </arm_group>
  <intervention>
    <intervention_type>Behavioral</intervention_type>
    <intervention_name>Multimodality information comprehension</intervention_name>
    <description>Evaluate various aspects of multimodality presentation of materials through text-to-speech systems used by people with aphasia.</description>
    <arm_group_label>Multimodality information Comprehension</arm_group_label>
  </intervention>
  <eligibility>
    <criteria>
      <textblock>
        Inclusion Criteria:

          -  Clinical diagnosis of aphasia with reading comprehension impairment resulting from
             stroke

          -  Age 19-90 years

          -  At least 6 months post stroke

          -  American English is primary language

        Exclusion Criteria:

          -  Presence of hearing impairment (i.e., prescribed bilateral hearing aids or failed
             hearing screening)

          -  Presence of vision or motor impairments as determined by screening task described
             below.

          -  History of neurological or developmental (reading or learning) impairment other than
             stroke as determined by self- or family-report.
      </textblock>
    </criteria>
    <gender>All</gender>
    <minimum_age>19 Years</minimum_age>
    <maximum_age>90 Years</maximum_age>
    <healthy_volunteers>No</healthy_volunteers>
  </eligibility>
  <overall_official>
    <last_name>Kelly Knollman-Porter, PhD</last_name>
    <role>Principal Investigator</role>
    <affiliation>Miami University</affiliation>
  </overall_official>
  <overall_contact>
    <last_name>Kelly Knollman-Porter, PhD</last_name>
    <phone>513-529-2504</phone>
    <email>knollmkk@miamioh.edu</email>
  </overall_contact>
  <overall_contact_backup>
    <last_name>Saraj Wallace, PhD</last_name>
    <phone>412-39604129</phone>
    <email>wallaces@duq.edu</email>
  </overall_contact_backup>
  <verification_date>April 2018</verification_date>
  <!-- For several months we've had both old and new date name tags                             -->
  <!-- Now, the old date names have been dropped.                                               -->
  <!-- The new date name replacements are:                                                      -->
  <!--     OLD (gone)                                        NEW (in use)                       -->
  <!--   lastchanged_date                         becomes   last_update_submitted               -->
  <!--   firstreceived_date                       becomes   study_first_submitted               -->
  <!--   firstreceived_results_date               becomes   results_first_submitted             -->
  <!--   firstreceived_results_disposition_date   becomes   disposition_first_submitted         -->
  <study_first_submitted>October 12, 2017</study_first_submitted>
  <study_first_submitted_qc>October 12, 2017</study_first_submitted_qc>
  <study_first_posted type="Actual">October 17, 2017</study_first_posted>
  <last_update_submitted>April 20, 2018</last_update_submitted>
  <last_update_submitted_qc>April 20, 2018</last_update_submitted_qc>
  <last_update_posted type="Actual">April 23, 2018</last_update_posted>
  <responsible_party>
    <responsible_party_type>Sponsor</responsible_party_type>
  </responsible_party>
  <keyword>aphasia</keyword>
  <keyword>comprehension</keyword>
  <keyword>text-to-speech</keyword>
  <keyword>social validity</keyword>
  <condition_browse>
    <!-- CAUTION:  The following MeSH terms are assigned with an imperfect algorithm            -->
    <mesh_term>Aphasia</mesh_term>
  </condition_browse>
  <patient_data>
    <sharing_ipd>No</sharing_ipd>
    <ipd_description>We will not be sharing the data because of possible breach of privacy given the small number of local people with aphasia.</ipd_description>
  </patient_data>
  <!-- Results have not yet been posted for this study                                          -->
</clinical_study>

