<clinical_study>
  <!-- This xml conforms to an XML Schema at:
    https://clinicaltrials.gov/ct2/html/images/info/public.xsd -->
  <required_header>
    <download_date>ClinicalTrials.gov processed this data on May 29, 2018</download_date>
    <link_text>Link to the current ClinicalTrials.gov record.</link_text>
    <url>https://clinicaltrials.gov/show/NCT03058133</url>
  </required_header>
  <id_info>
    <org_study_id>69HCL16_0674</org_study_id>
    <nct_id>NCT03058133</nct_id>
  </id_info>
  <brief_title>Gender in Face-Voice Integration</brief_title>
  <acronym>Face-Voice</acronym>
  <official_title>Neural Correlates of Multimodal Face/Voice Processing in a Gender Task.</official_title>
  <sponsors>
    <lead_sponsor>
      <agency>Hospices Civils de Lyon</agency>
      <agency_class>Other</agency_class>
    </lead_sponsor>
  </sponsors>
  <source>Hospices Civils de Lyon</source>
  <oversight_info>
    <has_dmc>No</has_dmc>
    <is_fda_regulated_drug>No</is_fda_regulated_drug>
    <is_fda_regulated_device>No</is_fda_regulated_device>
  </oversight_info>
  <brief_summary>
    <textblock>
      Bayesian models of perception represent a promising approach to describe information
      processing by the brain. Predictive coding hypothesizes a process in which top-down
      expectations are continuously compared across multiple hierarchical levels with bottom-up
      sensory inputs and the differences or error signals are propagated in a bottom-up direction.
      The investigators hypothesize that strong expectations, are best investigated in expert
      processes such as face and voice recognition in humans. Individuals in complex social systems
      need to extract socially relevant information in a fast and efficient manner; hence, the
      majority of humans constitute face, voice and gender experts. Nevertheless, linking such
      combined abilities to brain activity with regards to the predictive coding hypothesis has not
      been attempted.Our results suggest asymmetric contributions of visual and auditory signals to
      the gender classification task. This sensitive psychophysical procedure is implemented in a
      decoding approach using fMRI and multi-voxel pattern analysis (MVPA). The investigators plan
      to test whether cortical areas implicated in processing auditory and visual gender signals
      show similar asymmetries.
    </textblock>
  </brief_summary>
  <overall_status>Recruiting</overall_status>
  <start_date type="Actual">May 20, 2016</start_date>
  <completion_date type="Anticipated">May 20, 2018</completion_date>
  <primary_completion_date type="Anticipated">April 20, 2018</primary_completion_date>
  <phase>N/A</phase>
  <study_type>Interventional</study_type>
  <has_expanded_access>No</has_expanded_access>
  <study_design_info>
    <intervention_model>Single Group Assignment</intervention_model>
    <primary_purpose>Basic Science</primary_purpose>
    <masking>None (Open Label)</masking>
  </study_design_info>
  <primary_outcome>
    <measure>Identify neural correlates (fMRI) of face / voice interaction in a gender classification task</measure>
    <time_frame>Maximum 90 days between inclusion of the subject and the 1st fMRI session (1h1 / 2). Then maximum 90 days before the 2nd session (1h1 / 2).</time_frame>
    <description>Classical functional analyses (GLM) and advanced statistical analyses of brain activations (BrainVoyager and Matlab softwares).</description>
  </primary_outcome>
  <primary_outcome>
    <measure>Identify neural correlates (fMRI) of face / voice respective contribution in a gender classification task</measure>
    <time_frame>Maximum 90 days between inclusion of the subject and the 1st fMRI session (1h1 / 2). Then maximum 90 days before the 2nd session (1h1 / 2).</time_frame>
    <description>Classical functional analyses (GLM) and advanced statistical analyses of brain activations</description>
  </primary_outcome>
  <number_of_arms>1</number_of_arms>
  <enrollment type="Anticipated">40</enrollment>
  <condition>Healthy</condition>
  <arm_group>
    <arm_group_label>fMRI study</arm_group_label>
    <arm_group_type>Other</arm_group_type>
  </arm_group>
  <intervention>
    <intervention_type>Other</intervention_type>
    <intervention_name>fMRI study</intervention_name>
    <description>Functional brain activations of face-voice processing during a gender task</description>
    <arm_group_label>fMRI study</arm_group_label>
  </intervention>
  <eligibility>
    <criteria>
      <textblock>
        Inclusion Criteria:

          -  Healthy men and women, right-handed

          -  No neurological antecedent

          -  Signed informed consent

        Exclusion Criteria:

          -  Pregnant women

          -  Volunteers with MRI contraindications: persons using a pacemaker or insulin pump,
             persons with a metallic prosthesis or an intracerebral clip, as well as claustrophobic
             subjects, neurosensory stimulator or implantable defibrillator, cochlear implants,
             body Foreign ferromagnetic ocular or cerebral close to nerve structures, agitation of
             the subject (non-cooperating or agitated subjects), ventriculoperitoneal neurosurgical
             bypass valves, dental apparatus.

          -  Persons under guardianship, curatorship or any other administrative or judicial
             measure of deprivation of rights or liberty, as well as persons of legal age protected
             by law.

          -  Participants refusing to be informed of the results of the medical examination
             (inclusion).

          -  Participants refusing to be informed of the possible detection of an anomaly.
      </textblock>
    </criteria>
    <gender>All</gender>
    <minimum_age>18 Years</minimum_age>
    <maximum_age>40 Years</maximum_age>
    <healthy_volunteers>Accepts Healthy Volunteers</healthy_volunteers>
  </eligibility>
  <overall_official>
    <last_name>Alain NICOLAS, MD</last_name>
    <role>Principal Investigator</role>
    <affiliation>Le VINATIER</affiliation>
  </overall_official>
  <overall_contact>
    <last_name>Alain NICOLAS, MD</last_name>
    <phone>04 37 91 54 80</phone>
    <email>Alain.NICOLAS@ch-le-vinatier.fr</email>
  </overall_contact>
  <overall_contact_backup>
    <last_name>Peggy Gerardin, PhD</last_name>
    <phone>04 72 91 34 95</phone>
    <email>peggy.gerardin@inserm.fr</email>
  </overall_contact_backup>
  <location>
    <facility>
      <name>Le VINATIER</name>
      <address>
        <city>Bron</city>
        <zip>69 500</zip>
        <country>France</country>
      </address>
    </facility>
    <status>Recruiting</status>
    <contact>
      <last_name>ALAIN NICOLAS, MD</last_name>
      <phone>04 37 91 54 80</phone>
      <email>Alain.NICOLAS@ch-le-vinatier.fr</email>
    </contact>
    <contact_backup>
      <last_name>PEGGY GERARDIN, PhD</last_name>
      <phone>04 72 91 34 95</phone>
      <email>peggy.gerardin@inserm.fr</email>
    </contact_backup>
  </location>
  <location_countries>
    <country>France</country>
  </location_countries>
  <reference>
    <citation>Gerardin P, Kourtzi Z, Mamassian P. Prior knowledge of illumination for 3D perception in the human brain. Proc Natl Acad Sci U S A. 2010 Sep 14;107(37):16309-14. doi: 10.1073/pnas.1006285107. Epub 2010 Aug 30.</citation>
    <PMID>20805488</PMID>
  </reference>
  <reference>
    <citation>Wacongne C, Changeux JP, Dehaene S. A neuronal model of predictive coding accounting for the mismatch negativity. J Neurosci. 2012 Mar 14;32(11):3665-78. doi: 10.1523/JNEUROSCI.5003-11.2012.</citation>
    <PMID>22423089</PMID>
  </reference>
  <reference>
    <citation>Pegado F, Comerlato E, Ventura F, Jobert A, Nakamura K, Buiatti M, Ventura P, Dehaene-Lambertz G, Kolinsky R, Morais J, Braga LW, Cohen L, Dehaene S. Timing the impact of literacy on visual processing. Proc Natl Acad Sci U S A. 2014 Dec 9;111(49):E5233-42. doi: 10.1073/pnas.1417347111. Epub 2014 Nov 24.</citation>
    <PMID>25422460</PMID>
  </reference>
  <reference>
    <citation>Markov NT, Ercsey-Ravasz M, Van Essen DC, Knoblauch K, Toroczkai Z, Kennedy H. Cortical high-density counterstream architectures. Science. 2013 Nov 1;342(6158):1238406. doi: 10.1126/science.1238406. Review.</citation>
    <PMID>24179228</PMID>
  </reference>
  <reference>
    <citation>Charrier C, Knoblauch K, Maloney LT, Bovik AC, Moorthy AK. Optimizing multiscale SSIM for compression via MLDS. IEEE Trans Image Process. 2012 Dec;21(12):4682-94. doi: 10.1109/TIP.2012.2210723. Epub 2012 Jul 30.</citation>
    <PMID>22868568</PMID>
  </reference>
  <reference>
    <citation>Gerardin P, Devinck F, Dojat M, Knoblauch K. Contributions of contour frequency, amplitude, and luminance to the watercolor effect estimated by conjoint measurement. J Vis. 2014 Apr 10;14(4). pii: 9. doi: 10.1167/14.4.9.</citation>
    <PMID>24722563</PMID>
  </reference>
  <verification_date>April 2017</verification_date>
  <!-- For several months we've had both old and new date name tags                             -->
  <!-- Now, the old date names have been dropped.                                               -->
  <!-- The new date name replacements are:                                                      -->
  <!--     OLD (gone)                                        NEW (in use)                       -->
  <!--   lastchanged_date                         becomes   last_update_submitted               -->
  <!--   firstreceived_date                       becomes   study_first_submitted               -->
  <!--   firstreceived_results_date               becomes   results_first_submitted             -->
  <!--   firstreceived_results_disposition_date   becomes   disposition_first_submitted         -->
  <study_first_submitted>February 8, 2017</study_first_submitted>
  <study_first_submitted_qc>February 15, 2017</study_first_submitted_qc>
  <study_first_posted type="Actual">February 20, 2017</study_first_posted>
  <last_update_submitted>April 26, 2017</last_update_submitted>
  <last_update_submitted_qc>April 26, 2017</last_update_submitted_qc>
  <last_update_posted type="Actual">April 28, 2017</last_update_posted>
  <responsible_party>
    <responsible_party_type>Sponsor</responsible_party_type>
  </responsible_party>
  <keyword>fMRI, perception, face-voice processing</keyword>
  <!-- Results have not yet been posted for this study                                          -->
</clinical_study>

