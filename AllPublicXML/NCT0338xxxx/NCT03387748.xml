<clinical_study>
  <!-- This xml conforms to an XML Schema at:
    https://clinicaltrials.gov/ct2/html/images/info/public.xsd -->
  <required_header>
    <download_date>ClinicalTrials.gov processed this data on May 29, 2018</download_date>
    <link_text>Link to the current ClinicalTrials.gov record.</link_text>
    <url>https://clinicaltrials.gov/show/NCT03387748</url>
  </required_header>
  <id_info>
    <org_study_id>S61109</org_study_id>
    <nct_id>NCT03387748</nct_id>
  </id_info>
  <brief_title>Cognitive Skills and Iconic Gestures</brief_title>
  <official_title>Role of Semantic Processing and Visuospatial Skills in Production of Iconic Gestures</official_title>
  <sponsors>
    <lead_sponsor>
      <agency>Universitaire Ziekenhuizen Leuven</agency>
      <agency_class>Other</agency_class>
    </lead_sponsor>
  </sponsors>
  <source>Universitaire Ziekenhuizen Leuven</source>
  <oversight_info>
    <has_dmc>No</has_dmc>
    <is_fda_regulated_drug>No</is_fda_regulated_drug>
    <is_fda_regulated_device>No</is_fda_regulated_device>
  </oversight_info>
  <brief_summary>
    <textblock>
      In this study, cognitive skills will be identified that underlie the production of iconic
      gestures in individuals with language difficulties. Specifically, what is the role of
      nonverbal semantic processing and visuospatial skills in the use of iconic gestures?
    </textblock>
  </brief_summary>
  <detailed_description>
    <textblock>
      Individuals with language difficulties (e.g., vocabulary or forming sentences) can find it
      difficult to communicate and express their thoughts. Speech-language therapists sometimes
      encourage individuals with language difficulties to use hand gestures. By using gestures
      these individuals may find it easier to express their thoughts and their communication
      partners may find it easier to comprehend them. The researchers aim to answer the question:
      which skills are needed to produce highly comprehensible gestures? The answers to this
      question can inspire future language therapy for individuals with language difficulties.

      Task1. Participants sees 30 items from the Boston Naming Task one by one. The researcher
      explains that she can not see the screen. When an image appears, the examiner asks the
      participant to describe the item without speaking, but by using hand gestures. These gesture
      versions are recorded on video. The researcher indicates which gesture strategy the
      participant used with each executed gesture (i.e., sketch, shape, object, or deictic). In
      addition, 200 adults with a typical development assess the intelligibility of each gesture.
      The recordings are presented one by one in a random order. The evaluators must write down
      what concept the person depicts on the video. By adding the correct responses per
      participant, each participant receives a skill score. This skill score is related to the
      individual results of cognitive testing.

      Task2. Participants watch a cartoon. They tell the story to the researcher who &quot;has never
      seen the cartoon and does not know what is happening&quot;. Participants do not receive
      instructions on the use of gestures. This storytelling task is recorded on video. The
      researchers will write this down and note which gestures are being produced. The videos are
      used to calculate two variables: the ratio of the number of gestures to words, and the ratio
      of gestures that are replacements of speech to all gestures (both speech replacement and
      complementary to speech). These variables are related to the results of the cognitive tests.

      Task3. The researcher starts a 1-on-1 interview (10 minutes) with the participant. This
      conversation partly proceeds according to a semi-structured script: a few questions have been
      drawn up in advance. Each question or comment contains two content words that make a gesture
      possible. During half of the scripted questions, the researcher will not use any gesture.
      During the other half, the researcher will produce the two gestures. As with a
      semi-structured interview, the researcher ensures a natural conversation. The conversations
      are recorded on video. The researcher transcribes the interviews and indicates whether the
      participant takes over the gestures of the researcher. Each time a script gesture is
      presented, the examiner indicates whether the participant has responded by applying the
      spoken word and / or the gesture. By involving the cognitive test results, it can be analyzed
      whether people with higher semantic processing and higher visual-spatial skills take over
      from others more often than those with weaker semantic processing skills and weaker
      visual-spatial skills.
    </textblock>
  </detailed_description>
  <overall_status>Not yet recruiting</overall_status>
  <start_date type="Anticipated">March 2018</start_date>
  <completion_date type="Anticipated">October 2020</completion_date>
  <primary_completion_date type="Anticipated">October 2020</primary_completion_date>
  <phase>N/A</phase>
  <study_type>Interventional</study_type>
  <has_expanded_access>No</has_expanded_access>
  <study_design_info>
    <intervention_model>Single Group Assignment</intervention_model>
    <intervention_model_description>non-factorial, cross-sectional study (with control group)</intervention_model_description>
    <primary_purpose>Basic Science</primary_purpose>
    <masking>None (Open Label)</masking>
  </study_design_info>
  <primary_outcome>
    <measure>Gesture iconicity</measure>
    <time_frame>One observation per participant, 2 years to collect data for all participants</time_frame>
    <description>Likert scale score: understandability of each gesture that is performed. Range of each score: 1 (label: not understandable) to 5 (highly understandable) Summed score is used (range 30/150, with 150 highest performance) .</description>
  </primary_outcome>
  <secondary_outcome>
    <measure>Gesture rate</measure>
    <time_frame>One testing per participant, over period of 2 years for all participants</time_frame>
    <description>Rate of iconic gestures per word during narrative task</description>
  </secondary_outcome>
  <secondary_outcome>
    <measure>Gesture strategy</measure>
    <time_frame>One testing per participant, over period of 2 years for all participants</time_frame>
    <description>Rate of iconic gesture strategies: proportion of deictic gestures, proportion of shaping gestures, proportion of handling gestures, and proportion of drawing gestures</description>
  </secondary_outcome>
  <number_of_arms>1</number_of_arms>
  <enrollment type="Anticipated">20</enrollment>
  <condition>Gestures</condition>
  <arm_group>
    <arm_group_label>Gesture elicitation</arm_group_label>
    <arm_group_type>Experimental</arm_group_type>
    <description>Observation: hand gesture elicitation task</description>
  </arm_group>
  <intervention>
    <intervention_type>Behavioral</intervention_type>
    <intervention_name>Gesture elicitation</intervention_name>
    <description>Participants are required to gesture with their hands (and not speaking) one by one 30 pictures from the Boston Naming Task which appear on a laptop screen.
Participants retell a cartoon to the researcher
The researcher initiates a 10-min spontaneous conversation.
These three tasks are video-recorded.</description>
    <arm_group_label>Gesture elicitation</arm_group_label>
  </intervention>
  <eligibility>
    <criteria>
      <textblock>
        Inclusion Criteria:

          -  Moderate Intellectual disability

          -  Down syndrome

        Exclusion Criteria:

          -  neurodegenerative disorder

          -  non-corrected severe hearing impairment

          -  non-corrected severe visual impairment

          -  active knowledge of a sign language or manual signing system
      </textblock>
    </criteria>
    <gender>All</gender>
    <minimum_age>16 Years</minimum_age>
    <maximum_age>45 Years</maximum_age>
    <healthy_volunteers>Accepts Healthy Volunteers</healthy_volunteers>
  </eligibility>
  <verification_date>December 2017</verification_date>
  <!-- For several months we've had both old and new date name tags                             -->
  <!-- Now, the old date names have been dropped.                                               -->
  <!-- The new date name replacements are:                                                      -->
  <!--     OLD (gone)                                        NEW (in use)                       -->
  <!--   lastchanged_date                         becomes   last_update_submitted               -->
  <!--   firstreceived_date                       becomes   study_first_submitted               -->
  <!--   firstreceived_results_date               becomes   results_first_submitted             -->
  <!--   firstreceived_results_disposition_date   becomes   disposition_first_submitted         -->
  <study_first_submitted>December 18, 2017</study_first_submitted>
  <study_first_submitted_qc>December 22, 2017</study_first_submitted_qc>
  <study_first_posted type="Actual">January 2, 2018</study_first_posted>
  <last_update_submitted>December 22, 2017</last_update_submitted>
  <last_update_submitted_qc>December 22, 2017</last_update_submitted_qc>
  <last_update_posted type="Actual">January 2, 2018</last_update_posted>
  <responsible_party>
    <responsible_party_type>Sponsor</responsible_party_type>
  </responsible_party>
  <!-- Results have not yet been posted for this study                                          -->
</clinical_study>

