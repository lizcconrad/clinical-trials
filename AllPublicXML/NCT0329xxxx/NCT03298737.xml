<clinical_study>
  <!-- This xml conforms to an XML Schema at:
    https://clinicaltrials.gov/ct2/html/images/info/public.xsd -->
  <required_header>
    <download_date>ClinicalTrials.gov processed this data on May 29, 2018</download_date>
    <link_text>Link to the current ClinicalTrials.gov record.</link_text>
    <url>https://clinicaltrials.gov/show/NCT03298737</url>
  </required_header>
  <id_info>
    <org_study_id>RSRB00068408</org_study_id>
    <nct_id>NCT03298737</nct_id>
  </id_info>
  <brief_title>Visual Attention and Eye Movements</brief_title>
  <official_title>Visual Attention and Eye Movements</official_title>
  <sponsors>
    <lead_sponsor>
      <agency>University of Rochester</agency>
      <agency_class>Other</agency_class>
    </lead_sponsor>
  </sponsors>
  <source>University of Rochester</source>
  <oversight_info>
    <has_dmc>No</has_dmc>
    <is_fda_regulated_drug>No</is_fda_regulated_drug>
    <is_fda_regulated_device>No</is_fda_regulated_device>
  </oversight_info>
  <brief_summary>
    <textblock>
      The purpose of this study is to provide information about how the brain processes sensory
      inputs using visual stimuli throughout various psychophysical experiments.
    </textblock>
  </brief_summary>
  <detailed_description>
    <textblock>
      This laboratory studies visual perception with a focus on the interaction between eye
      movements and attention. It is well established that attending to a stimulus can profoundly
      alter perception. For example, attending to a speaker at a crowded party can almost
      completely filter background both in terms of auditory noise and visual distractions.
      Although laboratory studies have traditionally investigated the effects of attentional
      changes in the absence of eye movements, under natural conditions, visual attention is often
      accompanied by orienting movements to direct our head and eyes towards the relevant objects
      of interest. Recent work has suggested that these orienting movements affect perception in a
      manner similar to covert attention. The proposed studies will investigate how eye movements
      contribute to perception and attention.

      The research covered by this protocol combines traditional &quot;button-press&quot; psychophysics with
      non-invasive eye-tracking to investigate the interaction between eye movements and
      perception. Subjects will perform simple perceptual tasks, such as judging the orientation or
      direction of a visual stimulus, while their eye position is monitored with a video
      eye-tracker. This approach (combining psychophysics and eye-tracking) is flexible, low risk,
      and fast when compared with neurophysiological studies. However, by focusing on low-level
      perceptual tasks, the results will be interpretable in the context of larger studies of
      neurophysiological responses in the visual system.

      The investigators hope that this basic research will ultimately have both applied and
      clinical significance. For example, understanding how perception is influenced by attention
      and eye-movements in neurotypical populations may provide non-invasive and naturalistic ways
      to identify and diagnose psychiatric disorders. Additionally, understanding how eye-movements
      interact with sensory encoding has the potential to improve machine learning algorithms for
      vision and navigation (These are not a part of the current study, but a potential future
      impact).
    </textblock>
  </detailed_description>
  <overall_status>Recruiting</overall_status>
  <start_date type="Actual">October 26, 2017</start_date>
  <completion_date type="Anticipated">January 1, 2020</completion_date>
  <primary_completion_date type="Anticipated">January 1, 2020</primary_completion_date>
  <study_type>Observational</study_type>
  <has_expanded_access>No</has_expanded_access>
  <study_design_info>
    <observational_model>Cohort</observational_model>
    <time_perspective>Prospective</time_perspective>
  </study_design_info>
  <primary_outcome>
    <measure>Pursuit eye movements to peripheral moving stimuli</measure>
    <time_frame>baseline</time_frame>
    <description>Pursuit eye movements are smooth eye movements with slow velocities (&lt; 15 degs/sec) that track the motion of visual stimuli when they are at the center of the visual field (Madelain and Krauzlis, J. of Vision, 2003). Here we will test the prediction that pursuit eye movements begin to track the motion of the stimulus located peripherally as an eye movement moves to the stimulus. The null hypothesis is that there will be no effect of the peripheral stimulus motion on the pursuit eye movements. We will measure eye movements using an infra-red eye tracker (Arrington, Inc) from 500 or more trials collected in each session. The distribution of pursuit eye movements will be computed for each subject to evaluate if there is significant pursuit along the direction of stimulus motion around the time of the saccade. The mean per participant will be determined and group effects evaluated.</description>
  </primary_outcome>
  <number_of_groups>1</number_of_groups>
  <enrollment type="Anticipated">20</enrollment>
  <condition>Vision, Ocular</condition>
  <arm_group>
    <arm_group_label>Correct to normal vision population</arm_group_label>
  </arm_group>
  <intervention>
    <intervention_type>Behavioral</intervention_type>
    <intervention_name>Covert Spatial Attention</intervention_name>
    <description>During behavioral sessions, subjects will sit in a dark room and view a video monitor placed at the minimum of 57 cm distance away from the subject. Staff will be present throughout all the testing to assist the subject and monitor equipment that is used for tracking their eye position. Subjects will be asked to maintain their heads in a stable position of rest in order to insure accurate tracking of their eye position. To stabilize their head, subjects will either use a &quot;chin rest&quot; in which they position their chin on a soft pad mounted in front of a video screen, or they may use a &quot;bite bar.&quot;</description>
    <arm_group_label>Correct to normal vision population</arm_group_label>
  </intervention>
  <eligibility>
    <study_pop>
      <textblock>
        Healthy participants age 18-65 with corrected to normal vision
      </textblock>
    </study_pop>
    <sampling_method>Non-Probability Sample</sampling_method>
    <criteria>
      <textblock>
        Inclusion Criteria:

          -  Age between 18-65

          -  Corrected-to-normal vision

          -  No known diagnosis of visual or auditory disorder or impairment

        Exclusion Criteria:

          -  Does not have corrected-to-normal vision

          -  Unable to understand and follow the instructions given of the study

          -  Known diagnosis of visual or auditory disorder or impairment
      </textblock>
    </criteria>
    <gender>All</gender>
    <minimum_age>18 Years</minimum_age>
    <maximum_age>65 Years</maximum_age>
    <healthy_volunteers>Accepts Healthy Volunteers</healthy_volunteers>
  </eligibility>
  <overall_contact>
    <last_name>Sunwoo Kwon, MS</last_name>
    <phone>585-276-7865</phone>
    <email>s.kwon@rochester.edu</email>
  </overall_contact>
  <location>
    <facility>
      <name>Brain and Cognitive Sciences, University of Rochester</name>
      <address>
        <city>Rochester</city>
        <state>New York</state>
        <zip>14604</zip>
        <country>United States</country>
      </address>
    </facility>
    <status>Recruiting</status>
    <contact>
      <last_name>Sunwoo Kwon, PhD</last_name>
    </contact>
  </location>
  <location_countries>
    <country>United States</country>
  </location_countries>
  <reference>
    <citation>Madelain L, Krauzlis RJ. Pursuit of the ineffable: perceptual and motor reversals during the tracking of apparent motion. J Vis. 2003 Nov 18;3(11):642-53.</citation>
    <PMID>14765950</PMID>
  </reference>
  <verification_date>November 2017</verification_date>
  <!-- For several months we've had both old and new date name tags                             -->
  <!-- Now, the old date names have been dropped.                                               -->
  <!-- The new date name replacements are:                                                      -->
  <!--     OLD (gone)                                        NEW (in use)                       -->
  <!--   lastchanged_date                         becomes   last_update_submitted               -->
  <!--   firstreceived_date                       becomes   study_first_submitted               -->
  <!--   firstreceived_results_date               becomes   results_first_submitted             -->
  <!--   firstreceived_results_disposition_date   becomes   disposition_first_submitted         -->
  <study_first_submitted>September 20, 2017</study_first_submitted>
  <study_first_submitted_qc>September 26, 2017</study_first_submitted_qc>
  <study_first_posted type="Actual">October 2, 2017</study_first_posted>
  <last_update_submitted>November 9, 2017</last_update_submitted>
  <last_update_submitted_qc>November 9, 2017</last_update_submitted_qc>
  <last_update_posted type="Actual">November 14, 2017</last_update_posted>
  <responsible_party>
    <responsible_party_type>Principal Investigator</responsible_party_type>
    <investigator_affiliation>University of Rochester</investigator_affiliation>
    <investigator_full_name>Jude Mitchell</investigator_full_name>
    <investigator_title>Assistant Professor</investigator_title>
  </responsible_party>
  <patient_data>
    <sharing_ipd>No</sharing_ipd>
  </patient_data>
  <!-- Results have not yet been posted for this study                                          -->
</clinical_study>

